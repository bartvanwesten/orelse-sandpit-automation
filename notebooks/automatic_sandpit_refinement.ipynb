{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68890323",
   "metadata": {},
   "source": [
    "# Automatic Sandpit Refinement for D-Flow FM\n",
    "\n",
    "This notebook provides an automated workflow for refining unstructured grids around sandpit areas in D-Flow FM models. The refinement process uses Casulli refinement to gradually transition from coarse background resolution to fine target resolution.\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. **Configuration**: Set file paths and refinement parameters\n",
    "2. **Load Grid and Polygons**: Load the grid and create/load sandpit polygons\n",
    "3. **Plan Refinement**: Analyze grid resolution and generate refinement zones\n",
    "4. **Execute Refinement**: Apply Casulli refinement to the grid\n",
    "5. **Monitor Quality** (Optional): Analyze grid quality metrics\n",
    "6. **Setup Partitioned Model**: Create partitioned model with refined grid\n",
    "7. **Modify Restart Variables**: Apply sandpit excavation to bed levels in restart files\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- `dfm_tools`\n",
    "- `meshkernel`\n",
    "- `numpy`\n",
    "- `matplotlib`\n",
    "- `shapely`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1b0505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Configuration and Setup\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to Python path (for local installations)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Print location of the environment / interpreter\n",
    "print(f\"Python interpreter: {sys.executable}\")\n",
    "    \n",
    "import numpy as np\n",
    "import dfm_tools as dfmt\n",
    "import matplotlib.pyplot as plt\n",
    "import xugrid as xu\n",
    "import xarray as xr\n",
    "import psutil\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from scipy.spatial.distance import cdist\n",
    "import scipy.interpolate\n",
    "import meshkernel\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Import utility functions\n",
    "from src.polygon_utils import InteractivePolygonDrawer, load_pol_file, save_pol_file, generate_refinement_polygons, expand_polygon_outward, add_shape_to_polygon\n",
    "from src.refinement_utils import compute_refinement_steps, apply_casulli_refinement, print_refinement_summary\n",
    "from src.visualization_utils import plot_grid, is_codespace, plot_restart_results\n",
    "from src.monitoring_utils import analyze_grid_quality, plot_grid_quality\n",
    "from src.restart_utils import setup_partitioned_model, load_restart_files, save_restart_files\n",
    "from src.netcdf_utils import export_refined_grid\n",
    "\n",
    "# INPUT: Filenames\n",
    "nc_file ='dcsm_0_125nm_2ref_bathygr7_RGFGRID_net.nc' #'DCSM-FM_0_5nm_grid_20220310_depth_20220517_net.nc'\n",
    "\n",
    "# INPUT: Toggle options\n",
    "visualization_bool = False          # Set to True to enable visualization\n",
    "monitor_quality = False             # Set to True if you to analyze the quality of the grid\n",
    "use_existing_pol_file = True        # Set to True to use an existing polygon file (no new polygons will be created)\n",
    "plot_bathymetry = False             # Set to True to plot bathymetry in the background of interactive plot\n",
    "setup_partitioned_model_bool = True # Set to True to setup partitioned model\n",
    "\n",
    "# INPUT: Refinement parameters\n",
    "target_resolution = 100  # Target resolution in meters for the finest refinement level\n",
    "buffer_around_sandpit = 250  # Buffer around sandpit polygons in meters\n",
    "N = 6  # Number of transition cells\n",
    "\n",
    "# INPUT: DFM model and installation paths\n",
    "model_dir = Path(\"../data/model/coldstart_test\")\n",
    "original_mdu = \"DCSM-FM_0_5nm.mdu\"\n",
    "dimr_config = \"dimr_config.xml\"\n",
    "dflowfm_exe = Path(\"p:/11211460-msc-gw-coupling/02_engines/2025.01/x64/bin/run_dflowfm.bat\")\n",
    "dimr_parallel_exe = Path(\"p:/11211460-msc-gw-coupling/02_engines/2025.01/x64/bin/run_dimr_parallel.bat\")\n",
    "n_partitions = 10\n",
    "\n",
    "# INPUT: Digging parameters\n",
    "dig_depth = 5.0        # meters to lower bed level\n",
    "slope = 0.03            # slope ratio for smooth transitions (default: 0.1)\n",
    "\n",
    "# Auto-detect correct data path based on current working directory\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "   # Running from notebooks directory (Codespace)\n",
    "   data_path = os.path.join('..', 'data')\n",
    "else:\n",
    "   # Running from project root (local Jupyter)\n",
    "   data_path = 'data'\n",
    "\n",
    "# INPUT: File paths (input & output)\n",
    "nc_path = os.path.join(data_path, 'input', nc_file)\n",
    "input_pol_file = os.path.join(data_path, 'input', 'sandpits.pol')\n",
    "output_pol_file = os.path.join(data_path, 'output', 'sandpits.pol')\n",
    "xyz_output_path = os.path.join(data_path, 'output', 'bathymetry.xyz')\n",
    "output_dir = os.path.join(data_path, 'output')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Environment detection\n",
    "if is_codespace():\n",
    "    print(\"Running in GitHub Codespace\")\n",
    "else:\n",
    "    print(\"Running locally\")\n",
    "\n",
    "print(\"Configuration loaded\")\n",
    "print(f\"   Target: {target_resolution}m | Buffer: {buffer_around_sandpit}m | Transitions: {N}\")\n",
    "print(f\"   Model: {model_dir} | Partitions: {n_partitions}\")\n",
    "print(f\"   Digging: {dig_depth}m depth | {slope} slope ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132430e9",
   "metadata": {},
   "source": [
    "## Step 1: Load Grid and Define Sandpit Polygons\n",
    "\n",
    "This step loads the D-Flow FM grid and either:\n",
    "- Loads existing sandpit polygons from a .pol file\n",
    "- Opens an interactive drawing tool to create new polygons\n",
    "\n",
    "The polygons define the areas where refinement will be applied.\n",
    "\n",
    "**Note**: Interactive polygon drawing is only available when running locally, not in Codespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34b2f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Grid and Create/Load Polygons\n",
    "\n",
    "# Check if NetCDF file exists\n",
    "if not os.path.exists(nc_path):\n",
    "    raise FileNotFoundError(f\"Required file not found: {nc_path}\")\n",
    "\n",
    "# Load grid data\n",
    "print(\"Loading grid...\")\n",
    "ugrid = dfmt.open_partitioned_dataset(nc_path)\n",
    "ugrid_original = dfmt.open_partitioned_dataset(nc_path)  # Keep original for later comparison\n",
    "\n",
    "# Convert to meshkernel objects for consistent plotting and refinement\n",
    "mk_object = ugrid.grid.meshkernel\n",
    "mk_backup = ugrid_original.grid.meshkernel  # Keep backup\n",
    "\n",
    "# Handle polygon input/creation\n",
    "if use_existing_pol_file:\n",
    "    # Load existing polygon file\n",
    "    if os.path.exists(input_pol_file):\n",
    "        polygons = load_pol_file(input_pol_file)\n",
    "        print(f\"Loaded {len(polygons)} sandpit polygons from file\")\n",
    "    else:\n",
    "        print(f\"File {input_pol_file} not found, switching to interactive mode\")\n",
    "        use_existing_pol_file = False\n",
    "\n",
    "if not use_existing_pol_file:\n",
    "    # Interactive polygon creation\n",
    "    if is_codespace():\n",
    "        print(\"Interactive polygon drawing not available in Codespace\")\n",
    "        print(\"   Please create a sandpits.pol file or run locally for interactive drawing\")\n",
    "        raise RuntimeError(\"Interactive mode not supported in Codespace\")\n",
    "    \n",
    "    # Create an interactive plot\n",
    "    %matplotlib tk\n",
    "    print(\"Opening interactive polygon drawing tool...\")\n",
    "    print(\"   Instructions: RIGHT CLICK â†' add vertex | ENTER â†' finish polygon | Close window when done\")\n",
    "    \n",
    "    drawer = InteractivePolygonDrawer(ugrid, nc_path, plot_bathymetry)\n",
    "    polygons = drawer.draw_polygons()\n",
    "    \n",
    "    if polygons:\n",
    "        output_file = os.path.join(output_dir, 'sandpits.pol')\n",
    "        save_pol_file(polygons, output_file)\n",
    "        print(f\"Saved {len(polygons)} polygons to {output_file}\")\n",
    "\n",
    "\n",
    "# Uncomment to add one new shape to the existing polygon file\n",
    "add_shape_to_polygon(input_pol_file, output_pol_file, 'rectangle', 4.0, 52.2, width=0.03, height=0.02, rotation=45)\n",
    "polygons = load_pol_file(output_pol_file)  # Reload polygons after adding new shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d58feed",
   "metadata": {},
   "source": [
    "## Step 2: Plan Refinement Strategy\n",
    "\n",
    "This step:\n",
    "1. Analyzes the current grid resolution within the sandpit polygons\n",
    "2. Calculates the number of refinement steps needed\n",
    "3. Generates refinement zones with automatic overlap detection and merging\n",
    "4. Visualizes the refinement plan\n",
    "\n",
    "The refinement zones are created from coarse (outer) to fine (inner) resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b552b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Plan Refinement Strategy\n",
    "\n",
    "# Analyze grid resolution and compute refinement steps\n",
    "print(\"Analyzing grid resolution...\")\n",
    "refinement_params = compute_refinement_steps(ugrid, target_resolution, polygons)\n",
    "\n",
    "# Generate refinement polygons with overlap merging\n",
    "print(\"Generating refinement zones...\")\n",
    "(all_refinement_polygons, all_original_polygons, \n",
    " buffer_polygons, expansions) = generate_refinement_polygons(\n",
    "    polygons, refinement_params, buffer_around_sandpit, N)\n",
    "\n",
    "# Store original buffer polygons for visualization\n",
    "original_buffer_polygons = []\n",
    "for i, polygon in enumerate(polygons):\n",
    "    polygon_array = np.array(polygon)\n",
    "    center_lat = np.mean(polygon_array[:, 1])\n",
    "    expanded_polygon = expand_polygon_outward(polygon, buffer_around_sandpit, center_lat)\n",
    "    original_buffer_polygons.append(expanded_polygon)\n",
    "\n",
    "# Visualize refinement plan\n",
    "if visualization_bool:\n",
    "    print(\"Visualizing refinement plan...\")\n",
    "    if not is_codespace():\n",
    "        %matplotlib inline\n",
    "    plot_grid(mk_object, polygons, all_refinement_polygons, all_original_polygons,\n",
    "            buffer_polygons, refinement_params['envelope_sizes_m'], refinement_params['n_steps'],\n",
    "            original_buffer_polygons=original_buffer_polygons,\n",
    "            title='Refinement Plan: Sandpit Polygons and Merged Refinement Zones')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9bd57c",
   "metadata": {},
   "source": [
    "## Step 3: Execute Grid Refinement\n",
    "\n",
    "This step applies Casulli refinement to the meshkernel object using the generated refinement zones. The refinement is applied from outside to inside (coarse to fine) to ensure smooth transitions.\n",
    "\n",
    "After refinement, the refined grid is visualized showing the final mesh structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b298e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Execute Grid Refinement\n",
    "\n",
    "# Apply Casulli refinement\n",
    "print(\"Executing refinement...\")\n",
    "apply_casulli_refinement(mk_object, all_refinement_polygons)\n",
    "\n",
    "# Visualize refined grid\n",
    "if visualization_bool:\n",
    "    print(\"Visualizing refined grid...\")\n",
    "    if not is_codespace():\n",
    "        %matplotlib inline\n",
    "    plot_grid(mk_object, polygons, all_refinement_polygons, all_original_polygons,\n",
    "            buffer_polygons, refinement_params['envelope_sizes_m'], refinement_params['n_steps'],\n",
    "            title='Refined Grid: Final Result with Casulli Refinement')\n",
    "\n",
    "# Print refinement summary\n",
    "print_refinement_summary(polygons, all_refinement_polygons, \n",
    "                        refinement_params['envelope_sizes_m'], \n",
    "                        refinement_params['n_steps'], buffer_polygons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87140b1c",
   "metadata": {},
   "source": [
    "## Step 4: Monitor Grid Quality (Optional)\n",
    "\n",
    "This optional step analyzes the quality of the refined grid by examining:\n",
    "- **Resolution**: Face areas converted to characteristic lengths\n",
    "- **Smoothness**: Ratio of adjacent cell sizes (target < 1.4)\n",
    "- **Orthogonality**: Deviation from 90° angles (target < 0.01)\n",
    "\n",
    "**Note**: This analysis can be computationally intensive for large grids, especially in Codespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ef16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: (Optional) Monitor Grid Quality\n",
    "if monitor_quality:\n",
    "    print(\"Analyzing grid quality metrics...\")\n",
    "    quality_data = analyze_grid_quality(mk_object, ugrid_original, all_refinement_polygons, polygons)\n",
    "    \n",
    "    print(\"Creating quality visualization...\")\n",
    "    if not is_codespace():\n",
    "        %matplotlib inline\n",
    "        plot_grid_quality(quality_data, all_refinement_polygons, target_resolution)\n",
    "    else:\n",
    "        print(\"Apparently the kernel crashes when trying to plot this in a Codespace environment...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_notes",
   "metadata": {},
   "source": [
    "## Step 5: Export Refined Grid\n",
    "\n",
    "This step exports the refined grid to a RGFGRID-compatible NetCDF file with automatic versioning to prevent overwriting existing files. The saved file contains complete UGRID topology including all connectivity arrays required by D-Flow FM.\n",
    "\n",
    "This refined grid serves as the foundation for the partitioned model setup and subsequent restart file generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "additional_ops",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Export refined grid to NetCDF with proper naming and compatibility\n",
    "\n",
    "output_refined_nc, ugrid_complete = export_refined_grid(\n",
    "    mk_object=mk_object,\n",
    "    original_nc_file=nc_file, \n",
    "    output_dir=output_dir,\n",
    "    suffix=\"_ref\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5a5dfd-9ce4-41df-88d0-09fae8f79320",
   "metadata": {},
   "source": [
    "## Step 6: Setup Partitioned Model\n",
    "\n",
    "This step creates a partitioned D-Flow FM model using the refined grid:\n",
    "\n",
    "1. **Create temporary files**: Generate temporary MDU and DIMR config files with appropriate settings\n",
    "2. **Partition grid**: Apply domain decomposition using D-Flow FM partitioning\n",
    "3. **Generate restart files**: Run a short model simulation to create initial restart files\n",
    "\n",
    "The process creates all necessary files for running the refined model in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f129d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Setup Partitioned Model\n",
    "if setup_partitioned_model_bool:\n",
    "    print(f\"Setting up partitioned model with {n_partitions} domains...\")\n",
    "    \n",
    "    # Run complete partitioning workflow\n",
    "    results = setup_partitioned_model(\n",
    "        model_dir=model_dir,\n",
    "        original_mdu=model_dir / original_mdu,\n",
    "        dimr_config=model_dir / dimr_config,\n",
    "        refined_grid_nc=Path(output_refined_nc),\n",
    "        dflowfm_exe=dflowfm_exe,\n",
    "        dimr_parallel_exe=dimr_parallel_exe,\n",
    "        n_partitions=n_partitions\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"Partitioned model setup skipped (set setup_partitioned_model_bool=True to enable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step7_doc",
   "metadata": {},
   "source": [
    "## Step 7: Modify Variables in Restart Files\n",
    "\n",
    "This final step applies sandpit excavation by modifying the bed levels in the restart files generated from Step 6:\n",
    "\n",
    "1. **Load restart files**: Read all partition restart files from the temporary model run\n",
    "2. **Modify bed levels**: Apply excavation within sandpit polygons using configured dig depth and slope parameters\n",
    "3. **Save modified files**: Export the modified restart files for use in production runs\n",
    "4. **Visualize results**: Plot the bed level modifications to verify the excavation pattern\n",
    "\n",
    "The modified restart files can be used as initial conditions for D-Flow FM simulations with the excavated sandpit geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd916517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Modify Variables in Restart Files\n",
    "\n",
    "# 1. Load restart files\n",
    "temp_mdu_name = results['temp_mdu'].stem  # DCSM-FM_0_5nm_temp\n",
    "restart_folder = model_dir / f\"DFM_OUTPUT_{temp_mdu_name}\"\n",
    "datasets = load_restart_files(restart_folder)\n",
    "\n",
    "# 2. Modify variables\n",
    "from src.modify_bedlevel import modify_bed_levels\n",
    "modified_datasets = modify_bed_levels(datasets, polygons, dig_depth, slope)\n",
    "\n",
    "# Add other variable modifications here:\n",
    "# from src.modify_variable_template import modify_water_level\n",
    "# modified_datasets = modify_water_level(modified_datasets, polygons, level_change_m=0.1)\n",
    "\n",
    "# 3. Save modified restart files\n",
    "restart_output_dir = Path(output_dir) / \"restart\"\n",
    "saved_files = save_restart_files(modified_datasets, restart_output_dir)\n",
    "\n",
    "# 4. Plot results\n",
    "plot_restart_results(modified_datasets, polygons, \"Modified Restart Files\")\n",
    "\n",
    "print(f\"Saved {len(saved_files)} modified restart files to {restart_output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}